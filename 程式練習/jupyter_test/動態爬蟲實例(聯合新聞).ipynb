{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#得到自己的user angent\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "\n",
    "\n",
    "\n",
    "# 指定 Edge WebDriver 的路径\n",
    "PATH = r\"C:\\\\selenium\\\\msedgedriver.exe\"  # 注意路径前加 r，表示原始字符串\n",
    "service = Service(PATH)\n",
    "\n",
    "# 初始化 Edge WebDriver、前往目标网址\n",
    "driver = webdriver.Edge(service=service)\n",
    "driver.get(\"https://www.nccu.edu.tw/app/home.php\")  # 要進去的網址\n",
    "\n",
    "# 等待几秒钟，方便观察页面加载情况\n",
    "import time\n",
    "time.sleep(5)\n",
    "\n",
    "# 获取当前浏览器的 User-Agent\n",
    "user_agent = driver.execute_script(\"return navigator.userAgent;\")\n",
    "print(\"User-Agent:\", user_agent)\n",
    "\n",
    "\n",
    "# 关闭浏览器\n",
    "driver.quit()\n",
    "\n",
    "# 使用获取到的 User-Agent\n",
    "HEADERS = {\n",
    "    'User-Agent': user_agent,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#爬所有的新聞\n",
    "import requests\n",
    "\n",
    "def get_all_news():\n",
    "    \"\"\"爬取所有新闻\"\"\"\n",
    "    base_url = \"https://udn.com/api/more\"\n",
    "    all_news = []\n",
    "    page_num = 1\n",
    "\n",
    "    while True:\n",
    "        query = f\"page={page_num}&channelId=1&cate_id=0&type=breaknews\"\n",
    "        news_list_url = f\"{base_url}?{query}\"\n",
    "        print(news_list_url)\n",
    "\n",
    "        try:\n",
    "            response = requests.get(news_list_url)\n",
    "            response.raise_for_status()  # 检查请求是否成功\n",
    "            data = response.json()  # 解析返回的 JSON 数据\n",
    "\n",
    "            # 假设新闻列表在 'lists' 键中\n",
    "            news_list = data.get('lists', [])\n",
    "\n",
    "            # 如果返回的新闻列表为空，说明已经加载完所有数据\n",
    "            if not news_list:\n",
    "                print(\"没有更多数据\")\n",
    "                break\n",
    "\n",
    "            all_news.extend(news_list)  # 将当前页的新闻添加到总列表中\n",
    "            page_num += 1  # 准备加载下一页\n",
    "\n",
    "            # 如果返回的数据中包含分页信息，可以进一步判断\n",
    "            if 'has_more' in data and not data['has_more']:\n",
    "                print(\"已经加载完所有数据\")\n",
    "                break\n",
    "\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"请求第 {page_num} 页时出错: {e}\")\n",
    "            print(\"请检查网页链接的合法性，并确保网络连接正常。\")\n",
    "            break  # 如果请求失败，退出循环\n",
    "\n",
    "    return all_news\n",
    "\n",
    "# 调用函数获取所有新闻\n",
    "all_news = get_all_news()\n",
    "print(all_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存为 CSV 文件\n",
    "df.to_csv(r\"C:\\Users\\user\\OneDrive\\Desktop\\test\\news.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"CSV 文件已生成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#爬取新聞並變成csv檔\n",
    "#概念就是，是當我們網頁往下滾到底部後，會觸發網頁的 JavaScript 程式，讓它透過 Ajax 動態載入，將新聞資料一直載入進來。\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "import time\n",
    "\n",
    "page_num = 23  # 要爬取的页数\n",
    "\n",
    "def get_news_list(page_num):\n",
    "    \"\"\"爬取新闻列表\"\"\"\n",
    "    base_url = \"https://udn.com/api/more\"  # 修正后的 base_url\n",
    "\n",
    "    news_list = []\n",
    "    for page in range(page_num):\n",
    "        channelId = 1\n",
    "        cate_id = 0\n",
    "        type_ = 'breaknews'\n",
    "        query = f\"page={page+1}&channelId={channelId}&cate_id={cate_id}&type={type_}\"\n",
    "        news_list_url = base_url + '?' + query\n",
    "        print(news_list_url)\n",
    "        \n",
    "        try:\n",
    "            # 使用 requests 发起请求\n",
    "            response = requests.get(news_list_url)\n",
    "            response.raise_for_status()  # 检查请求是否成功\n",
    "            data = response.json()  # 解析返回的 JSON 数据\n",
    "            news_list.extend(data.get('lists', []))  # 假设新闻列表在 'lists' 键中\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"请求第 {page+1} 页时出错: {e}\")\n",
    "            print(\"请检查网页链接的合法性，并确保网络连接正常。\")\n",
    "            print(\"如果问题仍然存在，可以稍后重试。\")\n",
    "            break  # 如果请求失败，退出循环\n",
    "\n",
    "    return news_list\n",
    "\n",
    "# 调用函数获取新闻列表\n",
    "news_list = get_news_list(page_num)\n",
    "print(news_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成dataframe\n",
    "\n",
    "import pandas as pd\n",
    "# 将 JSON 数据转换为 DataFrame\n",
    "df = pd.DataFrame(news_list)\n",
    "\n",
    "# 提取所有標題，並將缺失值（NaN）排除\n",
    "text = \" \".join(df['title'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成文字雲\n",
    "import jieba\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义停用词\n",
    "stopwords = \"\"\"的\n",
    "了\n",
    "在\n",
    "是\n",
    "我\n",
    "有\n",
    "和\n",
    "不\n",
    "人\n",
    "都\n",
    "一\n",
    "對\n",
    "說\n",
    "要\n",
    "來\n",
    "這\n",
    "他\n",
    "也\n",
    "為\n",
    "以\n",
    "上\n",
    "下\n",
    "為什麼\n",
    "所以\n",
    "那\n",
    "把\n",
    "它\n",
    "你\n",
    "她\n",
    "我們的\n",
    "他們\n",
    "他們的\n",
    "來自\n",
    "可以\n",
    "去\n",
    "這些\n",
    "會\n",
    "還\n",
    "的\n",
    "為了\n",
    "如果\n",
    "但\n",
    "之後\n",
    "當\n",
    "會\n",
    "此\n",
    "其\n",
    "從\n",
    "等\n",
    "更多\n",
    "因\n",
    "己\n",
    "後\n",
    "變\n",
    "與\n",
    "又\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成\n",
    "# 将停用词保存到文件\n",
    "with open(\"stopwords.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(stopwords.strip())\n",
    "\n",
    "# 加载停用词\n",
    "stopwords_path = \"stopwords.txt\"\n",
    "def load_stopwords(stopwords_path):\n",
    "    with open(stopwords_path, 'r', encoding='utf-8') as f:\n",
    "        return set(f.read().splitlines())\n",
    "stopwords = load_stopwords(stopwords_path)\n",
    "\n",
    "\n",
    "# 使用 jieba 进行中文分词并过滤停用词\n",
    "segmented_text = \" \".join([word for word in jieba.cut(text) if word not in stopwords])\n",
    "\n",
    "# 设置中文字体路径\n",
    "font_path = r\"C:\\python\\字體\\LxgwWenKai-main\\fonts\\TTF\\LXGWWenKaiMono-Regular.ttf\"\n",
    "\n",
    "# 生成文字云\n",
    "wordcloud = WordCloud(\n",
    "    font_path=font_path,\n",
    "    width=800,  # 加大尺寸以获得更好的效果\n",
    "    height=800,\n",
    "    background_color='white',\n",
    "    mask=None,  # 如果需要使用遮罩，可以取消注释并设置为 taiwan_mask\n",
    "    contour_width=2,\n",
    "    contour_color='gray',\n",
    "    min_font_size=10,\n",
    "    max_font_size=100,\n",
    "    prefer_horizontal=0.7,\n",
    "    collocations=False\n",
    ").generate(segmented_text)\n",
    "\n",
    "# 显示文字云\n",
    "plt.figure(figsize=(12, 16))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# 保存为图片文件\n",
    "wordcloud.to_file(\"wordcloud.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
