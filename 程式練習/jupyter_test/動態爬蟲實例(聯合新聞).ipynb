{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#得到自己的user angent\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "\n",
    "\n",
    "\n",
    "# 指定 Edge WebDriver 的路径\n",
    "PATH = r\"C:\\\\selenium\\\\msedgedriver.exe\"  # 注意路径前加 r，表示原始字符串\n",
    "service = Service(PATH)\n",
    "\n",
    "# 初始化 Edge WebDriver、前往目标网址\n",
    "driver = webdriver.Edge(service=service)\n",
    "driver.get(\"https://www.nccu.edu.tw/app/home.php\")  # 要進去的網址\n",
    "\n",
    "# 等待几秒钟，方便观察页面加载情况\n",
    "import time\n",
    "time.sleep(5)\n",
    "\n",
    "# 获取当前浏览器的 User-Agent\n",
    "user_agent = driver.execute_script(\"return navigator.userAgent;\")\n",
    "print(\"User-Agent:\", user_agent)\n",
    "\n",
    "\n",
    "# 关闭浏览器\n",
    "driver.quit()\n",
    "\n",
    "# 使用获取到的 User-Agent\n",
    "HEADERS = {\n",
    "    'User-Agent': user_agent,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# 指定 Edge WebDriver 的路径\n",
    "PATH = r\"C:\\\\selenium\\\\msedgedriver.exe\"  # 注意路径前加 r，表示原始字符串\n",
    "service = Service(PATH)\n",
    "\n",
    "# 初始化 Edge WebDriver、前往目标网址\n",
    "driver = webdriver.Edge(service=service)\n",
    "driver.get(\"https://www.nccu.edu.tw/app/home.php\")  # 要進去的網址\n",
    "\n",
    "# 等待几秒钟，方便观察页面加载情况\n",
    "import time\n",
    "time.sleep(5)\n",
    "\n",
    "# 获取当前浏览器的 User-Agent\n",
    "user_agent = driver.execute_script(\"return navigator.userAgent;\")\n",
    "print(\"User-Agent:\", user_agent)\n",
    "\n",
    "\n",
    "# 关闭浏览器\n",
    "driver.quit()\n",
    "\n",
    "# 使用获取到的 User-Agent\n",
    "HEADERS = {\n",
    "    'User-Agent': user_agent,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#爬取新聞並變成csv檔\n",
    "#概念就是，是當我們網頁往下滾到底部後，會觸發網頁的 JavaScript 程式，讓它透過 Ajax 動態載入，將新聞資料一直載入進來。\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "import time\n",
    "\n",
    "def get_news_list(page_num=4):\n",
    "    \"\"\"爬取新闻列表\"\"\"\n",
    "    base_url = \"https://udn.com/api/more\"  # 修正后的 base_url\n",
    "\n",
    "    news_list = []\n",
    "    for page in range(page_num):\n",
    "        channelId = 1\n",
    "        cate_id = 0\n",
    "        type_ = 'breaknews'\n",
    "        query = f\"page={page+1}&channelId={channelId}&cate_id={cate_id}&type={type_}\"\n",
    "        news_list_url = base_url + '?' + query\n",
    "        print(news_list_url)\n",
    "        \n",
    "        try:\n",
    "            # 使用 requests 发起请求\n",
    "            response = requests.get(news_list_url)\n",
    "            response.raise_for_status()  # 检查请求是否成功\n",
    "            data = response.json()  # 解析返回的 JSON 数据\n",
    "            news_list.extend(data.get('lists', []))  # 假设新闻列表在 'lists' 键中\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"请求第 {page+1} 页时出错: {e}\")\n",
    "            print(\"请检查网页链接的合法性，并确保网络连接正常。\")\n",
    "            print(\"如果问题仍然存在，可以稍后重试。\")\n",
    "            break  # 如果请求失败，退出循环\n",
    "\n",
    "    return news_list\n",
    "\n",
    "# 调用函数获取新闻列表\n",
    "news_list = get_news_list(page_num=3)\n",
    "print(news_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#爬所有的新聞\n",
    "import requests\n",
    "\n",
    "def get_all_news():\n",
    "    \"\"\"爬取所有新闻\"\"\"\n",
    "    base_url = \"https://udn.com/api/more\"\n",
    "    all_news = []\n",
    "    page_num = 1\n",
    "\n",
    "    while True:\n",
    "        query = f\"page={page_num}&channelId=1&cate_id=0&type=breaknews\"\n",
    "        news_list_url = f\"{base_url}?{query}\"\n",
    "        print(news_list_url)\n",
    "\n",
    "        try:\n",
    "            response = requests.get(news_list_url)\n",
    "            response.raise_for_status()  # 检查请求是否成功\n",
    "            data = response.json()  # 解析返回的 JSON 数据\n",
    "\n",
    "            # 假设新闻列表在 'lists' 键中\n",
    "            news_list = data.get('lists', [])\n",
    "\n",
    "            # 如果返回的新闻列表为空，说明已经加载完所有数据\n",
    "            if not news_list:\n",
    "                print(\"没有更多数据\")\n",
    "                break\n",
    "\n",
    "            all_news.extend(news_list)  # 将当前页的新闻添加到总列表中\n",
    "            page_num += 1  # 准备加载下一页\n",
    "\n",
    "            # 如果返回的数据中包含分页信息，可以进一步判断\n",
    "            if 'has_more' in data and not data['has_more']:\n",
    "                print(\"已经加载完所有数据\")\n",
    "                break\n",
    "\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"请求第 {page_num} 页时出错: {e}\")\n",
    "            print(\"请检查网页链接的合法性，并确保网络连接正常。\")\n",
    "            break  # 如果请求失败，退出循环\n",
    "\n",
    "    return all_news\n",
    "\n",
    "# 调用函数获取所有新闻\n",
    "all_news = get_all_news()\n",
    "print(all_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 将 JSON 数据转换为 DataFrame\n",
    "df = pd.DataFrame(news_list)\n",
    "\n",
    "# 保存为 CSV 文件\n",
    "df.to_csv(r\"C:\\Users\\user\\OneDrive\\Desktop\\test\\news.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"CSV 文件已生成\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
